{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/popka/anaconda/lib/python2.7/site-packages/matplotlib/__init__.py:872: UserWarning: axes.color_cycle is deprecated and replaced with axes.prop_cycle; please use the latter.\n",
      "  warnings.warn(self.msg_depr % (key, alt_key))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as pl\n",
    "import seaborn as sns\n",
    "import sklearn.cross_validation as cv\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor,export_graphviz\n",
    "from DecisionTree import DecisionTree\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.ensemble import GradientBoostingRegressor as GBR\n",
    "from GradientBoosting import GradientBoosting as myGB\n",
    "# Plotting config\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FOLDER = \"data/\"\n",
    "FILES = [\n",
    "        \"iris.txt\", \"bezdekIris.txt\", \"wine.txt\", \"bupa.txt\", \"housing.txt\", \"auto-mpg.txt\", \"spam\"\n",
    "        ]\n",
    "FILE = \"spam\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Подготавливаем признаки и целевую функцию\n",
    "if FILE in FILES[:6]:\n",
    "    \n",
    "    df = pd.read_csv(FOLDER+FILE, sep=\",\", header=None)#, encoding=\"utf-8\", quoting=csv.QUOTE_NONNUMERIC)\n",
    "    \n",
    "    if FILE in FILES[:2]:\n",
    "        # ИРИСЫ\n",
    "        df[4] = pd.factorize(df[4])[0]\n",
    "        X = df[[0,1,2,3]].as_matrix()\n",
    "        y = df[4].as_matrix()\n",
    "\n",
    "    if FILE == FILES[2]:\n",
    "        x_indexes = [x for x in range(1,14)]\n",
    "        X = df[x_indexes].as_matrix()\n",
    "        y = df[0].as_matrix()\n",
    "\n",
    "    if FILE == FILES[3]:\n",
    "        X = df[[0,1,2,3,4,5]].as_matrix()\n",
    "        y = df[6]\n",
    "        \n",
    "    if FILE == FILES[4]:\n",
    "        df = pd.read_csv(FOLDER+FILE, sep=\" \", header=None)#, encoding=\"utf-8\", quoting=csv.QUOTE_NONNUMERIC)\n",
    "        X = df[df.columns[1:]].as_matrix()\n",
    "        y = df[df.columns[0]].as_matrix()\n",
    "        \n",
    "    if FILE == FILES[5]:\n",
    "        df = pd.read_csv(FOLDER+FILE, sep=\" \", header=None)#, encoding=\"utf-8\", quoting=csv.QUOTE_NONNUMERIC)\n",
    "        X = df[df.columns[1:-1]].as_matrix()\n",
    "        y = df[df.columns[0]].as_matrix()\n",
    "        \n",
    "    x_train, x_test, y_train, y_test = cv.train_test_split(X, y, test_size=0.25)\n",
    "\n",
    "else:\n",
    "    \n",
    "    df_train = pd.read_csv(FOLDER+FILE+\".train.txt\", sep=\" \", header=None)#, encoding=\"utf-8\", quoting=csv.QUOTE_NONNUMERIC)\n",
    "    df_test = pd.read_csv(FOLDER+FILE+\".test.txt\", sep=\" \", header=None)#, encoding=\"utf-8\", quoting=csv.QUOTE_NONNUMERIC)\n",
    "    x_train = df_train[df_train.columns[1:]].as_matrix()\n",
    "    y_train = df_train[df_train.columns[0]].as_matrix()\n",
    "    x_test = df_test[df_test.columns[1:]].as_matrix()\n",
    "    y_test = df_test[df_test.columns[0]].as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_curve(x, y, title):\n",
    "    \n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    plt.plot(x, y, color='blue', label='MyGB')\n",
    "    plt.ylim(0, max(y*1.03)+0.02)\n",
    "    plt.grid(True)\n",
    "    plt.xlabel(\"features count\", fontsize=15)\n",
    "    plt.ylabel(\"mse\", fontsize=15)\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    #plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сколько фичей отбираем "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedded "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_est=250\n",
    "max_depth=4\n",
    "rsm=False\n",
    "shrinkage=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.065097389117\n",
      "CPU times: user 20min 33s, sys: 2.59 s, total: 20min 36s\n",
      "Wall time: 20min 40s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/popka/anaconda/lib/python2.7/site-packages/numpy/core/_methods.py:59: RuntimeWarning: Mean of empty slice.\n",
      "  warnings.warn(\"Mean of empty slice.\", RuntimeWarning)\n",
      "/home/popka/anaconda/lib/python2.7/site-packages/numpy/core/_methods.py:82: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  warnings.warn(\"Degrees of freedom <= 0 for slice\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "my_gb = myGB(n_estimators=n_est, max_depth=max_depth, rsm=rsm, shrinkage=shrinkage)\n",
    "my_gb.fit(x_train, y_train)\n",
    "y_predict = my_gb.predict(x_test)\n",
    "print mse(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def aggregate_gains(node, feature_importance):\n",
    "    if node.is_leaf:\n",
    "        return\n",
    "    \n",
    "    gain = node.predicate.gain\n",
    "    feature_index = node.predicate.feature_id\n",
    "    feature_importance[feature_index] = gain\n",
    "    \n",
    "    aggregate_gains(node.left_node, feature_importance)\n",
    "    aggregate_gains(node.right_node, feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_importance = np.zeros(len(x_train.T))\n",
    "ensamble = my_gb._estimators\n",
    "for tree in ensamble:\n",
    "    aggregate_gains(tree._root, feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.047494489699602127, 95),\n",
       " (0.042150773108005524, 6),\n",
       " (0.033429037779569626, 19),\n",
       " (0.028516422957181931, 4),\n",
       " (0.026696523651480675, 7),\n",
       " (0.024460051208734512, 71),\n",
       " (0.018712038174271584, 64),\n",
       " (0.018295813351869583, 30),\n",
       " (0.016621118411421776, 15),\n",
       " (0.016550984233617783, 3),\n",
       " (0.015333914197981358, 31),\n",
       " (0.015091545879840851, 34),\n",
       " (0.014703515917062759, 53),\n",
       " (0.013742998242378235, 58),\n",
       " (0.012283220887184143, 59),\n",
       " (0.010555494576692581, 8),\n",
       " (0.0093645807355642319, 41),\n",
       " (0.0082793775945901871, 44),\n",
       " (0.0081197386607527733, 57),\n",
       " (0.0080301119014620781, 102),\n",
       " (0.0080185551196336746, 1),\n",
       " (0.0069031361490488052, 39),\n",
       " (0.00582143384963274, 40),\n",
       " (0.0049374401569366455, 24),\n",
       " (0.0049288328737020493, 22),\n",
       " (0.0046140635386109352, 18),\n",
       " (0.0039362385869026184, 38),\n",
       " (0.0037562530487775803, 43),\n",
       " (0.0033722412772476673, 21),\n",
       " (0.0031828256323933601, 9),\n",
       " (0.0030789165757596493, 92),\n",
       " (0.0030155307613313198, 2),\n",
       " (0.0027428208850324154, 26),\n",
       " (0.002675558440387249, 14),\n",
       " (0.0025639976374804974, 47),\n",
       " (0.0017780180787667632, 75),\n",
       " (0.0017490275204181671, 89),\n",
       " (0.0015673665329813957, 101),\n",
       " (0.0011820010840892792, 76),\n",
       " (0.0011515934020280838, 60)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zipped = zip(feature_importance, df_train.columns[1:])\n",
    "zipped.sort(key = lambda t: t[0], reverse=True)\n",
    "zipped[:N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "[(0.047494489699602127, 95),\n",
    " (0.042150773108005524, 6),\n",
    " (0.033429037779569626, 19),\n",
    " (0.028516422957181931, 4),\n",
    " (0.026696523651480675, 7),\n",
    " (0.024460051208734512, 71),\n",
    " (0.018712038174271584, 64),\n",
    " (0.018295813351869583, 30),\n",
    " (0.016621118411421776, 15),\n",
    " (0.016550984233617783, 3),\n",
    " (0.015333914197981358, 31),\n",
    " (0.015091545879840851, 34),\n",
    " (0.014703515917062759, 53),\n",
    " (0.013742998242378235, 58),\n",
    " (0.012283220887184143, 59),\n",
    " (0.010555494576692581, 8),\n",
    " (0.0093645807355642319, 41),\n",
    " (0.0082793775945901871, 44),\n",
    " (0.0081197386607527733, 57),\n",
    " (0.0080301119014620781, 102),\n",
    " (0.0080185551196336746, 1),\n",
    " (0.0069031361490488052, 39),\n",
    " (0.00582143384963274, 40),\n",
    " (0.0049374401569366455, 24),\n",
    " (0.0049288328737020493, 22),\n",
    " (0.0046140635386109352, 18),\n",
    " (0.0039362385869026184, 38),\n",
    " (0.0037562530487775803, 43),\n",
    " (0.0033722412772476673, 21),\n",
    " (0.0031828256323933601, 9),\n",
    " (0.0030789165757596493, 92),\n",
    " (0.0030155307613313198, 2),\n",
    " (0.0027428208850324154, 26),\n",
    " (0.002675558440387249, 14),\n",
    " (0.0025639976374804974, 47),\n",
    " (0.0017780180787667632, 75),\n",
    " (0.0017490275204181671, 89),\n",
    " (0.0015673665329813957, 101),\n",
    " (0.0011820010840892792, 76),\n",
    " (0.0011515934020280838, 60)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Посчитаем качество на сокращенном наборе фичей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "good_features = []\n",
    "for i in range(N):\n",
    "    good_features.append(zipped[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mse_array_embedded = []\n",
    "for i in range(1, len(good_features)+1):\n",
    "    features = good_features[:i]\n",
    "    X_train, X_test = x_train[:,features], x_test[:, features]\n",
    "    \n",
    "    my_gb = myGB(n_estimators=n_est, max_depth=max_depth, rsm=rsm, shrinkage=shrinkage)\n",
    "    my_gb.fit(X_train, y_train)\n",
    "    y_predict = my_gb.predict(X_test)\n",
    "    m = mse(y_test, y_predict)\n",
    "    mse_array_embedded.append(m)\n",
    "    print i, m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Сравним качество со Sklearn'ом "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gb = GradientBoostingRegressor(n_estimators=250)\n",
    "gb.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zipped = zip(gb.feature_importances_, df_train.columns[1:])\n",
    "zipped.sort(key = lambda t: t[0], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_features = []\n",
    "for i in range(N):\n",
    "    new_features.append(zipped[i][1]-1)\n",
    "    \n",
    "new_x_train = x_train[:,new_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gb = GradientBoostingRegressor(n_estimators=250)\n",
    "gb.fit(new_x_train, y_train)\n",
    "y_predict = my_gb.predict(x_test)\n",
    "print mse(y_test, y_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Считаем дисперсию. Удаляем фичи с малой дисперсией"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zipped_var = zip(np.var(x_train, axis=1), df_train.columns[1:])\n",
    "zipped_var.sort(key = lambda t: t[0], reverse=False)\n",
    "zipped_var[:N]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Считаем корреляцию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "corr_mat = df_train.corr().abs()\n",
    "plt.figure(figsize=(18, 18))\n",
    "plt.title(\"Correlation between features\")\n",
    "sns.heatmap(corr_mat, cmap=\"YlOrRd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Выберем признаки, похожие на ответ\n",
    "abs_corr_y = corr_mat[0]\n",
    "good_features = abs_corr_y.sort_values(ascending=False)[:N]\n",
    "good_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Найдем признаки, которых похожи на те, что мы отобрали. Их не берем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "min_cor = 0.7\n",
    "feature_indexes = good_features.index\n",
    "full_similar_features = []\n",
    "for idx in feature_indexes:\n",
    "    similiar_features = corr_mat[corr_mat[idx]>min_cor].index.values\n",
    "    # Удаляем значение idx из similiar_features\n",
    "    similiar_features = similiar_features[similiar_features != idx]\n",
    "    full_similar_features.extend(similiar_features)\n",
    "    print \"Feature \", idx, \" correlate with \", similiar_features\n",
    "    \n",
    "print full_similar_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for f in full_similar_features:\n",
    "    if f in good_features:\n",
    "        good_features = good_features.drop(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "good_features = list(good_features.index[1:]-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# чтобы не потерять\n",
    "print good_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mse_array_filtering=[]\n",
    "for i in range(1, len(good_features)+1):\n",
    "    features = good_features[:i]\n",
    "    X_train, X_test = x_train[:,features], x_test[:, features]\n",
    "    model = GBR(n_estimators=n_est, max_depth=max_depth, learning_rate=shrinkage)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_predicted=model.predict(X_test)\n",
    "    mse_array_filtering.append(mse(y_test, y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_curve(range(1, len(good_features)+1), np.asarray(mse_array), \"Filtering\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.ensemble import GradientBoostingRegressor as GBR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_est=250\n",
    "rsm=False\n",
    "shrinkage=0.1\n",
    "max_depth=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def measure_quality(X, y, k=3):\n",
    "    \n",
    "    kf = KFold(len(y), n_folds=k)\n",
    "    mse_array = []\n",
    "    for train, test in kf:\n",
    "        _X_train, _X_test, _y_train, _y_test = X[train], X[test], y[train], y[test]\n",
    "        model = GBR(n_estimators=n_est, max_depth=max_depth, learning_rate=shrinkage)\n",
    "        model.fit(_X_train, _y_train)\n",
    "        _y_predicted=model.predict(_X_test)\n",
    "        mse_array.append(mse(_y_test, _y_predicted))\n",
    "    \n",
    "    return float(sum(mse_array))/len(mse_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_best_feature(best_features, remaining_features, x_train, y_train):\n",
    "    \"\"\"\n",
    "    Выбираем лучшую фичу.\n",
    "    best_features - [1,5,10,...]фичи, которые уже были выбраны\n",
    "    remaining_features - [2,3,4,6,7,8,9,,...] оставшиеся фичи, которые уже были выбраны\n",
    "    \"\"\"\n",
    "    best_mse = sys.maxint\n",
    "    best_fea = None\n",
    "    print best_features, remaining_features\n",
    "\n",
    "    for f in remaining_features:\n",
    "        new_features = best_features + [f]\n",
    "        print new_features\n",
    "        new_mse = measure_quality(x_train[:,new_features], y_train)\n",
    "        \n",
    "        if new_mse < best_mse:\n",
    "            best_mse = new_mse\n",
    "            best_fea = f\n",
    "            \n",
    "    return best_fea, best_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "best_features=[]\n",
    "\n",
    "all_features=range(0, x_train.shape[1])\n",
    "print x_train.shape[1]\n",
    "best_mse=sys.maxint\n",
    "\n",
    "for f in all_features:\n",
    "    feature, cur_mse = find_best_feature(best_features, all_features, x_train, y_train)\n",
    "    \n",
    "    if cur_mse<best_mse:\n",
    "        print \"====================\"\n",
    "        print \"new_best_mse = \", cur_mse\n",
    "        best_mse=cur_mse\n",
    "        best_features.append(feature)\n",
    "        all_features.remove(feature)\n",
    "        print \"the_best_feature_list=\", best_features\n",
    "        print all_features\n",
    "        print \"////////////////\"\n",
    "    else:\n",
    "        print \"NOT_GOOD_FEATURES\"\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Считалось 5 часов на Sklern'e, с моей реализацией не считается!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#good_features = [48, 70, 53, 10, 101, 56, 55, 9, 71, 4, 76, 52, 16, 3, 6, 50, 65, 100]\n",
    "good_features = [48, 70, 53, 55, 52, 74, 29, 8, 71, 83, 10, 43, 4, 54, 41, 76, 35, 14, 9, 45, 51, 75, 60, 101]\n",
    "\n",
    "mse_array_wrapper=[]\n",
    "for i in range(1, len(good_features)+1):\n",
    "    features = good_features[:i]\n",
    "    X_train, X_test = x_train[:,features], x_test[:, features]\n",
    "    model = GBR(n_estimators=n_est, max_depth=max_depth, learning_rate=shrinkage)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_predicted=model.predict(X_test)\n",
    "    mse_array_wrapper.append(mse(y_test, y_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_curve(range(1, len(good_features)+1), np.asarray(mse_array), \"Wrapper\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
